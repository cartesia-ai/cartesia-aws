{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f19f703-ee36-412f-9229-670475ba64e6",
   "metadata": {},
   "source": [
    "# Use Sonic 3 with AWS Jumpstart\n",
    "\n",
    "This sample notebook shows you how to deploy Sonic 3 Models from Cartesia AI as an endpoint on Amazon SageMaker.\n",
    "\n",
    "Note: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Note: Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "\n",
    "Ensure that IAM role used has AmazonSageMakerFullAccess\n",
    "\n",
    "To deploy the ML model successfully using the steps in this notebook, ensure that either:\n",
    "\n",
    "Your IAM role has the following three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used:\n",
    "- aws-marketplace:ViewSubscriptions\n",
    "- aws-marketplace:Unsubscribe\n",
    "- aws-marketplace:Subscribe\n",
    "\n",
    "Or your AWS account has a subscription to the [Sonic 3 Sagemaker Listing](https://aws.amazon.com/marketplace/pp/prodview-w2bmik3jypagm). If so, skip the Subscribe to the model package step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb8afeb-4625-4eeb-b82d-0d8c67877515",
   "metadata": {},
   "source": [
    "## Subscribe to the model package\n",
    "\n",
    "To subscribe to the Sonic 3 Sagemaker Model Package:\n",
    "\n",
    "- Open the [Sonic 3 Sagemaker Model Package listing page](https://aws.amazon.com/marketplace/pp/prodview-w2bmik3jypagm)\n",
    "- On the AWS Marketplace listing, click on the Continue to subscribe button.\n",
    "- On the Subscribe to this software page, review and click on \"Accept Offer\" if you and your organization accept the EULA, pricing, and support terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c01a44-a914-4302-a276-f2c77a45ffce",
   "metadata": {},
   "source": [
    "## Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6dfc2-ba6c-4e11-b181-357044605a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import ModelPackage\n",
    "import boto3\n",
    "import asyncio\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "import wave\n",
    "from typing import Generator, Iterable, List\n",
    "\n",
    "ENDPOINT_NAME = \"sonic-3\"\n",
    "ROLE = \"<input the arn of the role you want to deploy the endpoint with>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4a182e-e654-4af6-ba13-cbf80e747e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PACKAGE_MAP = {\n",
    "    \"us-east-2\": 'arn:aws:sagemaker:us-east-2:570011132906:model-package/Sonic3-Sagemaker-V5'\n",
    "}\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "if region not in MODEL_PACKAGE_MAP.keys():\n",
    "    raise (\"UNSUPPORTED REGION\")\n",
    "package_arn = MODEL_PACKAGE_MAP[region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e58c99c-7494-4c35-86b1-0b64b5b4dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35884e2d-d959-492c-8303-9b303899371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the active account\n",
    "sts_client = boto3.client(\"sts\")\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "print(f\"Active account ID: {account_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b5196f-790d-42b2-9d23-b901ba6e02dc",
   "metadata": {},
   "source": [
    "Create a deployable ModelPackage. For Sonic 3, deploy onto an ml.g6e.xlarge instance. Specify it as instance_type below.\n",
    "\n",
    "Note: be sure to request service quota for `ml.g6e.xlarge for endpoint usage` under the `AWS Sagemaker Service`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd24eeb-0a26-4133-a8b0-58971dcdb82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelPackage(role=ROLE, model_package_arn=package_arn, sagemaker_session=sagemaker_session)\n",
    "\n",
    "instance_type=\"ml.g6e.xlarge\"\n",
    "deployed_model = model.deploy(initial_instance_count=1,instance_type=instance_type,endpoint_name=ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef60ef06-4c7e-4360-9b0d-ab052c878b69",
   "metadata": {},
   "source": [
    "You should now be able to see an ongoing endpoint creation in the AWS Sagemaker AI > Endpoints page on AWS console"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5865b230-00ed-4f89-9813-f839657294a1",
   "metadata": {},
   "source": [
    "## Run an inference request\n",
    "\n",
    "Lets feed some text to the model to get a inference response stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216fde20-3a18-4b1d-8437-167c30959e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c7e4f-f156-458e-b39b-a307aa11fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def events_from_aws_stream(\n",
    "    eventstream: Iterable[dict]\n",
    ") -> Generator[dict, None, None]:\n",
    "    \"\"\"\n",
    "    Convert SageMaker event stream (InvokeEndpointWithResponseStream) into json events\n",
    "    \"\"\"\n",
    "    buffered_text = \"\"\n",
    "    for event in eventstream:\n",
    "        if \"PayloadPart\" in event:\n",
    "            chunk_bytes = event[\"PayloadPart\"][\"Bytes\"]\n",
    "            chunk_text = chunk_bytes.decode(\"utf-8\")\n",
    "            if chunk_text.endswith(\"\\n\"):\n",
    "                yield json.loads(buffered_text + chunk_text)\n",
    "                buffered_text = \"\"\n",
    "            else:\n",
    "                buffered_text += chunk_text\n",
    "        elif \"ModelStreamError\" in event:\n",
    "            err = event[\"ModelStreamError\"]\n",
    "            raise RuntimeError(\n",
    "                f\"ModelStreamError: {err.get('ErrorCode')}: {err.get('Message')}\"\n",
    "            )\n",
    "        elif \"InternalStreamFailure\" in event:\n",
    "            raise RuntimeError(\"InternalStreamFailure from SageMaker\")\n",
    "        else:\n",
    "            # Unknown event type; ignore or log\n",
    "            continue\n",
    "\n",
    "\n",
    "async def get_tts_chunks_async():\n",
    "    def sync_stream():\n",
    "        \"\"\"Invokes the AWS response streaming endpoint and returns processed \n",
    "        responses from aws event stream\"\"\"\n",
    "        body_str = json.dumps(\n",
    "            {\n",
    "                \"context_id\": \"0\",\n",
    "                \"transcript\": \"\"\"\n",
    "In contemporary hyperdimensional differential-topological metamathematics,\n",
    "<speed ratio=\"1.5\"/><emotion value=\"mysterious\" /><volume ratio=\"4.0\"/>\n",
    "the quasi-isomorphic ultratranscendentalization of pseudoholomorphic manifolds\n",
    "necessitates an pistemologically recontextualized framework for analyzing\n",
    "infinitesimally perturbative tensorial eigen-decompositions.\n",
    "                \"\"\",\n",
    "                \"language\": \"en\",\n",
    "                \"output_format\": {\n",
    "                    \"container\": \"raw\",\n",
    "                    \"sample_rate\": 44100,\n",
    "                    \"encoding\": \"pcm\"\n",
    "                },\n",
    "                \"voice\": {\n",
    "                    \"mode\": \"id\",\n",
    "                    \"id\": \"bf0a246a-8642-498a-9950-80c35e9276b5\"\n",
    "                },\n",
    "                \"add_timestamps\": True,\n",
    "                \"add_phoneme_timestamps\": True\n",
    "            }\n",
    "        )\n",
    "\n",
    "        request_start_time = time.perf_counter()\n",
    "        response = sagemaker_runtime.invoke_endpoint_with_response_stream(\n",
    "            EndpointName=ENDPOINT_NAME,\n",
    "            Body=body_str,\n",
    "            ContentType=\"application/json\",\n",
    "            Accept=\"text/event-stream\",\n",
    "        )\n",
    "        print(\n",
    "            f\"[METRIC] InvokeEndpointWithResponseStream request time: {time.perf_counter() - request_start_time:.3f}s\"\n",
    "        )\n",
    "        print(response)\n",
    "\n",
    "        event_stream = response.get(\"Body\")\n",
    "        return events_from_aws_stream(event_stream)\n",
    "\n",
    "    audio_chunks = []\n",
    "    start_time = time.perf_counter()\n",
    "    first_chunk_time = None\n",
    "\n",
    "    async def consume_events():\n",
    "        nonlocal first_chunk_time\n",
    "\n",
    "        # Run the synchronous generator in a background thread\n",
    "        # Process response events and extract audio chunks\n",
    "        for chunk in await asyncio.to_thread(sync_stream):\n",
    "            if chunk[\"type\"] == \"chunk\":\n",
    "                if first_chunk_time is None:\n",
    "                    first_chunk_time = time.perf_counter()\n",
    "                    ttfa = first_chunk_time - start_time\n",
    "                    print(f\"[METRIC] Time to first audio: {ttfa:.3f}s\")\n",
    "\n",
    "                audio_chunks.append(chunk[\"data\"])\n",
    "            elif chunk[\"type\"] == \"timestamps\":\n",
    "                print(json.dumps(chunk[\"word_timestamps\"]))\n",
    "            elif chunk[\"type\"] == \"phoneme_timestamps\":\n",
    "                print(json.dumps(chunk[\"phoneme_timestamps\"]))\n",
    "            elif chunk[\"type\"] == \"done\":\n",
    "                print(\"[LOG] Stream finished.\")\n",
    "            elif chunk[\"type\"] == \"error\":\n",
    "                print(f\"[ERROR] {chunk['data']}\")\n",
    "\n",
    "    try:\n",
    "        await consume_events()\n",
    "    except sagemaker_runtime.exceptions.ModelError as e:\n",
    "        print(e.response['Message'])\n",
    "        print(e.response[\"OriginalStatusCode\"])\n",
    "\n",
    "    # Calculate full stream time\n",
    "    total_time = time.perf_counter() - start_time\n",
    "    print(f\"[METRIC] Total TTS stream time: {total_time:.3f}s\")\n",
    "\n",
    "    return audio_chunks\n",
    "\n",
    "chunks = await get_tts_chunks_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07444cc4-f71d-4d64-bde6-d18b8e0d059b",
   "metadata": {},
   "source": [
    "Now we can save the audio chunk to a local wav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8b45f-47a6-4ea3-9c94-445006a67c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_audio_chunks_to_wav(\n",
    "    chunks: List[str], output_file: str = \"output.wav\", sample_rate: int = 44100\n",
    "):\n",
    "    \"\"\"Decode base64 audio chunks and save as WAV file.\"\"\"\n",
    "    combined_audio = bytearray()\n",
    "    for chunk_data in chunks:\n",
    "        audio_bytes = base64.b64decode(chunk_data)\n",
    "        combined_audio.extend(audio_bytes)\n",
    "\n",
    "    with wave.open(output_file, \"wb\") as wav_file:\n",
    "        wav_file.setnchannels(1)\n",
    "        wav_file.setsampwidth(2)\n",
    "        wav_file.setframerate(sample_rate)\n",
    "        wav_file.writeframes(combined_audio)\n",
    "\n",
    "    file_size = len(combined_audio)\n",
    "    duration = len(combined_audio) / (sample_rate * 2)  # 16-bit = 2 bytes per sample\n",
    "    print(f\"[LOG] Saved WAV: {output_file} ({file_size} bytes, {duration:.2f}s)\")\n",
    "    return file_size, duration\n",
    "\n",
    "save_audio_chunks_to_wav(chunks, output_file=\"output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5dc84c-32a1-4f1a-b634-0b46bdbb5b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
